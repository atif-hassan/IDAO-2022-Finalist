{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82b369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\pymatgen\\core\\__init__.py:49: UserWarning: Error loading .pmgrc.yaml: [Errno 2] No such file or directory: 'C:\\\\Users\\\\atifh\\\\.pmgrc.yaml'. You may need to reconfigure your yaml file.\n",
      "  warnings.warn(f\"Error loading .pmgrc.yaml: {ex}. You may need to reconfigure your yaml file.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pymatgen.core import Lattice, Structure, Molecule\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from pymatgen.core.periodic_table import ElementBase, Element\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bc580",
   "metadata": {},
   "source": [
    "## Load the target variable as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a067b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train target variables\n",
    "df = pd.read_csv(\"dichalcogenides_public/targets.csv\")\n",
    "Y_dict = dict(zip(df[\"_id\"].values, df[\"band_gap\"].values))\n",
    "\n",
    "# Load the sample submission file\n",
    "# We will use the order of the ids to generate our own submission file\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "Y_test_ids = df[\"id\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dc987",
   "metadata": {},
   "source": [
    "# Define all functions here\n",
    "## 1. Performance metric\n",
    "## 2. Generate the vector representation of each structure as a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902b3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metric\n",
    "def metric(true, pred, e=0.02):\n",
    "    loss = np.abs(true-pred)\n",
    "    mask = [1 if i<e else 0 for i in loss]\n",
    "    return np.average(mask)\n",
    "\n",
    "def flatten(x):\n",
    "    x = x[0]\n",
    "    x_dash = list()\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            x_dash.append(x[i][j])\n",
    "    return x_dash\n",
    "\n",
    "# Creates a single vector representation of each structure\n",
    "def gen_data(files):\n",
    "    # USELESS FEATURES\n",
    "    # ================\n",
    "    # \"lattice\" all keys under this key have same values for all samples\n",
    "    # \"Charge\" is none for all structures\n",
    "    # structure.formula has duplicates with different band energy as output hence not useful\n",
    "    # structure.volume is same for all samples\n",
    "    # structure.frac_coords is same for all samples ???\n",
    "    # structure.DISTANCE_TOLERANCE is same for all samples\n",
    "    # structure.lattice.get_miller_index_from_coords(structure.cart_coords) significantly reduced performance\n",
    "    # structure.lattice.norm(structure.cart_coords) significantly reduced performance (either average or l2 norm)\n",
    "\n",
    "\n",
    "    # USEFUL FEATURES\n",
    "    # ================\n",
    "    # 1. The minimum number of elements (molecules) in a structure is 189, maximum is 192 and average is 190.51\n",
    "    #    We can directly use these values\n",
    "    # 2. Structure Density (structure.density.real)\n",
    "    # 3. The count of each species in every structure is a vector feature\n",
    "    # 4. structure.distance matrix has shape of (num_molecules x num_molecules). Contains distance between all molecules\n",
    "    #    Use maximum, minimum and average distances per row or overall from this matrix?\n",
    "    # 5. structure.atomic_numbers has one value for each molecule\n",
    "    # 6. structure.cart_coords is 3d position of each molecule\n",
    "\n",
    "    all_species = ['Mo', 'S', 'Se', 'W']\n",
    "    X_dict = dict()\n",
    "    for idx, file in tqdm(enumerate(files), total=len(files)):\n",
    "        # Convert raw data into json format\n",
    "        data = json.load(open(file, 'r'))\n",
    "        # Convert json format to pymatgen format\n",
    "        structure = Structure.from_dict(data)\n",
    "        # Convert structure to dataframe for extraction of some features\n",
    "        df = structure.as_dataframe()\n",
    "        # Distance matrix\n",
    "        dm = structure.distance_matrix\n",
    "        # Get all species in current structure\n",
    "        curr_species = [\"\".join([j for j in i if not j.isdigit()]) for i in structure.formula.split()]\n",
    "        # Get count of all species in current structure\n",
    "        curr_species_count = [int(\"\".join([j for j in i if j.isdigit()])) for i in structure.formula.split()]\n",
    "        # Create a count vector representation of species (extremely small improvement in final score)\n",
    "        count_vec = np.zeros(len(all_species))\n",
    "        for idx, i in enumerate(curr_species):\n",
    "            count_vec[all_species.index(i)] = curr_species_count[idx]\n",
    "        # Get the atomic numbers (extremely small improvement in final score)\n",
    "        atm_num = structure.atomic_numbers[:189]\n",
    "        bm = [Element(i).bulk_modulus for i in curr_species]\n",
    "        ym = [Element(i).youngs_modulus for i in curr_species]\n",
    "        dos = [Element(i).density_of_solid for i in curr_species]\n",
    "        clte = [Element(i).coefficient_of_linear_thermal_expansion for i in curr_species]\n",
    "        mp = [Element(i).melting_point for i in curr_species]\n",
    "        X_dict[file[file.rindex(\"\\\\\")+1:file.index(\".\")]] = [structure.density.real,\n",
    "                                                             np.average(dm),\n",
    "                                                             len(structure.atomic_numbers),\n",
    "                                                             sum([i*j for i, j in zip(bm, curr_species_count)]),\n",
    "                                                             sum([i*j for i, j in zip(ym, curr_species_count) if i is not None]),\n",
    "                                                             sum([i*j for i, j in zip(dos, curr_species_count) if i is not None]),\n",
    "                                                             sum([i*j for i, j in zip(clte, curr_species_count) if i is not None]),\n",
    "                                                             sum([i*j for i, j in zip(mp, curr_species_count) if i is not None]),\n",
    "                                                             np.average(np.sum(dm, axis=0)),\n",
    "                                                            ] + list(atm_num) + list(count_vec)\n",
    "    return X_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe775b",
   "metadata": {},
   "source": [
    "## Pair the generated features with corresponding target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ecc26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03de588574b44bbc9aa1d66e7dd2802e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f02403f32e4e5c8642a49bc5743a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (2966, 202)\n",
      "Test Data Shape: (2967, 202)\n"
     ]
    }
   ],
   "source": [
    "X_train_dict = gen_data(glob(\"dichalcogenides_public\\\\structures\\\\*.json\"))\n",
    "X_test_dict = gen_data(glob(\"dichalcogenides_private\\\\structures\\\\*.json\"))\n",
    "\n",
    "X_train, Y = list(), list()\n",
    "for lattice_id, feat in X_train_dict.items():\n",
    "    X_train.append(feat)\n",
    "    Y.append(Y_dict[lattice_id])\n",
    "X_train, Y = np.asarray(X_train), np.asarray(Y)\n",
    "print(\"Train Data Shape:\", X_train.shape)\n",
    "\n",
    "X_test = list()\n",
    "for id_ in Y_test_ids:\n",
    "    X_test.append(X_test_dict[id_])\n",
    "X_test = np.asarray(X_test)\n",
    "print(\"Test Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdfefe7",
   "metadata": {},
   "source": [
    "## Create Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1600fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2328) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1208)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 \n",
      "==========\n",
      "\tXGBoost:  0.8047138047138047\n",
      "\tRandomForest:  0.8164983164983165\n",
      "\tEnsemble:  0.8164983164983165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2334) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1206)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 \n",
      "==========\n",
      "\tXGBoost:  0.7740303541315345\n",
      "\tRandomForest:  0.8178752107925801\n",
      "\tEnsemble:  0.8128161888701517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2336) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1205)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 \n",
      "==========\n",
      "\tXGBoost:  0.7858347386172007\n",
      "\tRandomForest:  0.8026981450252951\n",
      "\tEnsemble:  0.8026981450252951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2314) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1216)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 \n",
      "==========\n",
      "\tXGBoost:  0.7875210792580101\n",
      "\tRandomForest:  0.8145025295109612\n",
      "\tEnsemble:  0.8111298482293423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2352) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1197)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 \n",
      "==========\n",
      "\tXGBoost:  0.806070826306914\n",
      "\tRandomForest:  0.8263069139966274\n",
      "\tEnsemble:  0.821247892074199\n",
      "\n",
      "\n",
      "Average Score XGBoost: 0.7916341606054927\n",
      "Average Score RandomForest: 0.8155762231647561\n",
      "Average Score Ensemble: 0.812878078139461\n"
     ]
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kfold = KFold(n_splits=num_splits, random_state=27, shuffle=True)\n",
    "scores1, scores2, scores3 = list(), list(), list()\n",
    "for index, (train, test) in enumerate(kfold.split(X_train)):\n",
    "    x_train, x_test = X_train[train], X_train[test]\n",
    "    y_train, y_test = Y[train], Y[test]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    inds = np.where(y_train<0.6)\n",
    "    y_classes = np.zeros(len(y_train))\n",
    "    y_classes[inds] = 1\n",
    "    x_train_e = np.concatenate((x_train, np.reshape(y_train, (-1, 1))), axis=1)\n",
    "    \n",
    "    minority = len(inds[0])\n",
    "    majority = len(y_train)-minority\n",
    "    \n",
    "    # Perform oversampling using SMOTE \n",
    "    sm = SMOTE(random_state=42, sampling_strategy={0:majority, 1:minority*2})\n",
    "    x_train_e, _ = sm.fit_resample(x_train_e, y_classes)\n",
    "    x_train, y_train = x_train_e[:,:-1], x_train_e[:,-1]\n",
    "    \n",
    "    model = ExtraTreesRegressor(random_state=27)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds1 = model.predict(x_test)\n",
    "    scores1.append(metric(y_test, preds1))\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=27, max_depth=9, criterion=\"absolute_error\", n_jobs=-1)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds2 = model.predict(x_test)\n",
    "    scores2.append(metric(y_test, preds2))\n",
    "    \n",
    "    scores3.append(metric(y_test, 0.1*preds1+0.9*preds2))\n",
    "    print(\"Fold\", index+1, \"\\n==========\")\n",
    "    print(\"\\tXGBoost: \", scores1[-1])\n",
    "    print(\"\\tRandomForest: \", scores2[-1])\n",
    "    print(\"\\tEnsemble: \", scores3[-1])\n",
    "    \n",
    "print(\"\\n\\nAverage Score XGBoost:\", sum(scores1)/len(scores1))\n",
    "print(\"Average Score RandomForest:\", sum(scores2)/len(scores2))\n",
    "print(\"Average Score Ensemble:\", sum(scores3)/len(scores3))\n",
    "\n",
    "# 0.8081540531793483\n",
    "# XGBoost: 0.8064\n",
    "# RandomForest: 0.8155762231647561"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f9ec4",
   "metadata": {},
   "source": [
    "## Finally predict and save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f764d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2916) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 1508)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inds = np.where(Y<0.6)\n",
    "Y_classes = np.zeros(len(Y))\n",
    "Y_classes[inds] = 1\n",
    "X_train_e = np.concatenate((X_train, np.reshape(Y, (-1, 1))), axis=1)\n",
    "\n",
    "minority = len(inds[0])\n",
    "majority = len(Y)-minority\n",
    "\n",
    "sm = SMOTE(random_state=42, sampling_strategy={0:majority, 1:minority*2})\n",
    "X_train_e, _ = sm.fit_resample(X_train_e, Y_classes)\n",
    "X_train, Y = X_train_e[:,:-1], X_train_e[:,-1]\n",
    "\n",
    "model = RandomForestRegressor(random_state=27, max_depth=9, n_estimators=100, criterion=\"absolute_error\", n_jobs=-1)\n",
    "model.fit(X_train, Y)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "fp = open(\"final_submission.csv\", \"w\")\n",
    "fp.write(\"id,predictions\\n\")\n",
    "for id_, pred in zip(Y_test_ids, preds):\n",
    "    fp.write(id_+\",\"+str(pred)+\"\\n\")\n",
    "fp.close()\n",
    "\n",
    "# Average Score: 0.8064682803300005 (XGBoost)\n",
    "# LB Score: 0.81873 (no OOF)\n",
    "# LB Score: 0.81671 (with OOF)\n",
    "\n",
    "# Average Score: 0.8101805009056273 (RandomForest)\n",
    "# LB Score: 0.82682\n",
    "\n",
    "# Average Score: 0.8081540531793483 (Ensemble)\n",
    "# LB Score: 0.82278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972bed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
